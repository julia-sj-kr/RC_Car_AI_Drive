----------------
### 손실함수

딥러닝 및 머신러닝에서 모델이 예측한 값과 실제 값 사이의 차이를 측정하는 함수입니다. `모델의 성능을 평가`하기 위해 사용되며, 학습 과정에서 이 값을 최소화하는 것이 목표입니다. 즉, 손실 함수는 모델이 얼마나 잘못 예측했는지를 수치로 표현해줍니다.
- __모델 평가__: 모델이 예측한 결과와 실제 결과 간의 차이를 측정합니다. 이 차이가 크다면 모델이 제대로 학습되지 않았음을 의미합니다.
- __학습의 목표__: 딥러닝 모델을 학습할 때 손실 함수는 매우 중요한 역할을 하며, 최적화 알고리즘(예: 경사 하강법, Adam Optimizer)은 이 손실 함수의 값을 최소화하여 모델의 성능을 개선합니다. 손실 함수가 최소화되면 모델의 예측 정확도는 증가합니다.
- __손실 함수의 종류__:
   - 회귀(Regression) 문제에서 사용하는 손실 함수(MeanSquaredError(), MeanAbsoluteError())
   - 분류(Classification) 문제에서 사용하는 손실 함수(BinaryCrossentropy(), CategoricalCrossentropy())
- __TensorFlow에서 손실 함수 사용 예시__
  ```
  import tensorflow as tf
  
  # 이진 분류 문제에서 사용할 예시 손실 함수
  loss_fn = tf.keras.losses.BinaryCrossentropy()
  
  # 실제 값 (예: 레이블)
  y_true = [0, 1, 0, 1]
  
  # 예측 값 (예: 모델의 출력)
  y_pred = [0.1, 0.9, 0.2, 0.8]
  
  # 손실 계산
  loss = loss_fn(y_true, y_pred)
  print('Loss:', loss.numpy())
  ```
  - 출력  
  ```
  Loss: 0.16425234
  ```
  이 예제에서 모델이 예측한 값과 실제 값의 차이를 이진 교차 엔트로피로 측정한 결과, 손실 값이 0.164로 계산되었습니다. 이 값이 작아질수록 모델이 더 정확하게 예측하고 있음을 나타냅니다.

----------------
